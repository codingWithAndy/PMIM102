{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'><tr>\n",
    "    <td style='background-color:red; text-align:center; color: white;'><!--Foundation<!--hr size='5' style='border-color:red; background-color:red;'--></td>\n",
    "    <td style='background-color:yellow; text-align:center;'><!--Level 1<!--hr size='5' style='border-color:yellow; background-color:yellow;'--></td>\n",
    "    <td style='background-color:orange; text-align:center;'><!--Level 2<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:green; text-align:center; color: white;'><!--Level 3<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:blue; text-align:center; color: white;'><!--Level 4<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:purple; text-align:center; color: white;'><!--Level 5<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:brown; text-align:center; color: white;'><!--Level 6<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:black; text-align:center; color: white;'><!--Level 7<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style='border-left:10px solid orange;'><tr>\n",
    "    <td style='padding-left:20px;'>\n",
    "        <h2><i>Swansea University Medical School</i><br/><b>MSc Health Data Science</b></h2>\n",
    "        <h3>PMIM-102 Introduction to Scientific Computing in Healthcare</h3>\n",
    "        <h1><b>Introduction to Programming in R</b></h1>\n",
    "        <h2><b>2. Programming with Statistics</b></h2>\n",
    "        <h2><i>Part 1: Probability.</i></h2>\n",
    "        <h3><i>September 2020</i></h3>\n",
    "    </td>\n",
    "    <td><img height='300' width='500' src='images/cover.jpg'/></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Aim__: Explore facilities in R for doing statistical analyses\n",
    "\n",
    "The aim of this session is to build upon the R basics of the previous session to explore the tools available in R for statistical analysis.\n",
    "\n",
    "### __A map of where we're going__\n",
    "\n",
    "1. <div style=\"background-color:yellow;\"><b>Probability and probability distributions</b> and plotting in R - uniform, binomial, poisson. The Central Limit Theorem.</div>\n",
    "\n",
    "1. <b>Descriptive statistics</b> - the normal distribution, expected value, independence, mean, variance, summary.\n",
    "\n",
    "1. <b>Hypothesis Testing</b> -  - confidence interval, standard error, p-value, degrees of freedom, (non) parametric..\n",
    "\n",
    "1. <b>Single Sample Analysis</b> - what is the mean value, is it what was expected, what is its uncertainty?\n",
    "\n",
    "1. <b>Comparing Two (or More) Samples</b> - comparing means, variances, frequencies and distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Concepts &amp; Definitions__\n",
    "\n",
    "### __Statistics__\n",
    "\n",
    "Statistics is often defined as 'numerical data' which somehow seems insufficient. It has something to do with numbers, the measurement of numerical data, probability and aggregation of the numbers over a population and making use of them to describe and infer.\n",
    "\n",
    "When we talk of numerical data, we usually select specific measurements taken on a sample from a population. Each of these measurements is a 'variable'\n",
    "\n",
    "### __Variables__\n",
    "\n",
    "These are the numbers. When we look at the population, we use variables to describe the members of the population. These variables can be qualitative (or categorical) and define classes, e.g. gender as male/female/undefined; eye-colour as blue, brown, grey, green; have or have not had a stroke. \n",
    "\n",
    "* _Qualitative_\n",
    "    + _Ordinal_ where the subjects can be ordered and any ties are due to lack of precision but not with any consistent meaning between the values.\n",
    "    + _Nominal_ where the subjects are grouped into several categories which are not ordered (other than arbitrarily) unless explicitly indicated.\n",
    "        + _Dichotomous_: a nominal scale with only two values e.g. dead or alive.\n",
    "\n",
    "They can be quantitative where they can be measured and this can be discrete (integers, counts) or continuous such as height or weight.\n",
    "\n",
    "* _Quantitative_\n",
    "    + _Continuous_\n",
    "        * Ratio - the ratio of two quantities has a meaning such as height.\n",
    "        * Interval - where the difference between two readings has a consistent meaning but the zero may be arbitrary so the ratio does not (e.g. temperature in Celsius). \n",
    "    + _Discrete_ where the data can only have specific values and cannot have intermediate values, e.g. integers\n",
    "    \n",
    "It is also important when deciding which analyses to use to know whether the variable represents a __count__ of events (where you know how often the event occurred but you don't know the number of times the event did _not_ occur e.g. the number of times you have been struck by lightning) or a __proportion__ (where you know the count and the total number of times the event might have occurred e.g. the number of people in this room who have been struck by lightning).\n",
    "\n",
    "When we get on to _modelling_ we will have two kinds of variables, response variables (the output variables of the analysis) and explanatory variables (the input variables to the analysis).\n",
    "\n",
    "Finally _survival_ analyses make us of event data - whether and when an event occurred.\n",
    "\n",
    "Note that these are not necessarily mutually exclusive and an interval scale is also ordinal. There is some overlap between continuous and discrete scales, for example, where continuous measurements, e.g. height, are recorded in discrete units, e.g. cm.\n",
    "\n",
    "See Bland, Chapter 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Probability__\n",
    "\n",
    "According to Bland there are several ways of looking at this and he takes the frequency approach: the probability that an event will happen is the proportion of the repetitions of an event that would occur under the specified circumstances. There is also the Bayesian interpretation where probability is considered the degree of belief in an event. The maths comes out the same in both cases (I think), but some analyses are easier to perform with one or the other interpretation.\n",
    "\n",
    "A __random variable__ is a variable that can take a variety of values each with a given probability e.g. a coin can take a value of HEAD or TAIL with equal probability, a dice, the values 1-6, again with equal probability, human height in a sample of the population is an example of a continuous random variable.\n",
    "\n",
    "### _Properties of Probability_\n",
    "\n",
    "1. A probability value lies between 0.0 and 1.0. An event that never happens has a probability of 0.0, whereas one that always happens has a probability of 1.0. A fair coin will land on 'heads' with a probability 0.5. Can we say that the probability of having a baby boy is ~0.51?\n",
    "1. If two events are __mutually exclusive__ i.e. if one happens, the other can't, the probability of either occurring is the sum of the probabilities.\n",
    "1. If two events are __independent__ i.e. if one happens, it has no effect on whether the other happens, the probability of both happening is the product of the probability of each happening.\n",
    "\n",
    "### _IID_\n",
    "\n",
    "A set of random variables are independent and identically distributed (IID) if they all have the same distibution function and are mutually independent. This is a useful concept as it leads to simpler maths and so you'll often find that a technique assumes IID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Combinations_\n",
    "\n",
    "You can count the number of combinations of _k_ items chosen from _n_, easily in R with `choose(n, k)`. If you want to actually generate these combinations, use `combn(items, k)` with a list of the items and the number you want to select (which gives you a matrix with the combinations in successive columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose(4, 2)\n",
    "#combn(c(1, 2, 3, 4), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might come across combinations when looking at the binomial distribution and yes/no or other discrete variables like coins and dice. In case you're wondering, permutations require a new library and slightly different output, but for the sake of completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##install.packages(\"combinat\")\n",
    "#library(combinat)\n",
    "#permn(c(1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Mean / Expected Value_\n",
    "\n",
    "The expected value (or expectation) of a discrete variable is the sum of all the possible values multiplied by the probability of each value:\n",
    "\n",
    "\\begin{equation*} E(X) = \\sum X \\times p_X \\end{equation*}\n",
    "\n",
    "So, for the tosses of two coins, we have:\n",
    "\n",
    "\\begin{equation*} E(X) = 0 \\times \\frac {1}{4} + 1 \\times \\frac {1}{2} + 2 \\times \\frac {1}{4} = 0 + \\frac {1}{2} + \\frac {1}{2} = 1 \\end{equation*}\n",
    "\n",
    "This is also known as the mean and we often use the symbol $\\mu$.\n",
    "\n",
    "### _Variance_\n",
    "\n",
    "The variance of a random variable is a measure of how much the values differ from the mean. It is calculated as the square of the difference from the mean times the probability of the value:\n",
    "\n",
    "\\begin{equation*} VAR(X) = {(0 - 1)}^2 \\times \\frac {1}{4} + {(1 - 1)}^2 \\times \\frac {1}{2} + {(2 - 1)}^2 \\times \\frac {1}{4} = {(-1)}^2 + \\frac {1}{4} + 1^2 \\times \\frac {1}{2} = \\frac {1}{2} \\end{equation*}\n",
    "\n",
    "At this point it is worth noting that:\n",
    "\n",
    "\\begin{equation*} VAR(X) = E(X^2 - {E(X)}^2) \\end{equation*}\n",
    "\n",
    "As variance is a squared value, it is often shown with the symbol $\\sigma^2$ where $\\sigma$ (sigma) is the __standard deviation__ which is sometimes a more useful statistic as it is directly comparable to the mean.\n",
    "\n",
    "\n",
    "### _z-score_\n",
    "\n",
    "Sometimes it is useful to define an effect size measure that you can compare across studies which use different measurements. One way to do this is with the z-score. The z-score of a value is the number of standard deviations the value is from the mean i.e. difference between the value and the mean divided by the standard deviation.\n",
    "\n",
    "\\begin{equation*} z = \\frac {x - \\mu}{\\sigma} \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Quiz__: What is the expected value of tossing one coin? What about the fifth head?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points to bear in mind here are:\n",
    "* adding a constant value to a variable adds that value to the mean and doesn't change the variance.\n",
    "* multiplying a variable by a constant, multiplies the mean and the standard deviation but multiplies the variance by the constant squared.\n",
    "* adding two variables results in the mean being the sum of the means and the variance is the sum of the variances (if independent).\n",
    "* multiplying variables is more complex but uncommon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Quantiles_\n",
    "\n",
    "Quantiles are a useful way to describe the distribution of data. They describe the proportion of data below a value (or the value below which there is a specified proportion of the data). So the median is the value at which half the data is above / below. The 99th centile has 99 percent of the values below it. The quartiles are frequently quoted: the values with 25% below (lower) and 75% below (upper). The inter-quartile range is often quoted to give a sense of spread. The classic way to present quantiles is with a boxplot which show min and max (excluding outliers), upper and lower quartiles and the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(1, 2))\n",
    "#v <- rnorm(1000)\n",
    "#boxplot(v, col='orange')\n",
    "#w <- c(rnorm(100, mean=1, sd=1), rnorm(100, mean=2, sd=2), rpois(100, lambda=6))\n",
    "#boxplot(w, col='light blue', notch=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise__: Plot both 'v' and 'w' on the same plot with with different colours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot(v, w, col=c('orange', 'light green'), notch=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align:center;\"><tr><td width=\"100\" height=\"20\" style=\"background-color:greenyellow\"></td><td width=\"100\" height=\"20\" style=\"background-color:hotpink\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Probability Distributions__\n",
    "\n",
    "The set of all the possible values of a random variable and the associated probabilities is the __probability distribution__ of that variable. There are a few very common distributions you are sure to come across as they correspond to the situation for particular types of variables.\n",
    "\n",
    "* Uniform distribution - equal chance for a series of values, die, coin etc.\n",
    "* Binomial distribution - n independent trials with each trial having a probability, p. n=1 is a Bernoulli distribution - e.g. a single coin toss.\n",
    "* Poisson distribution - the number of events that have occurred in a period.\n",
    "* Normal (Gaussian) distribution - the fundamental distribution in statistics - the result of the central-limit theorem.\n",
    "\n",
    "We'll review the first three here and the Normal distribution in the following notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Uniform Distribution\n",
    "The uniform distribution is constant for all possible values. It is the dist\n",
    "Just for reference so that we can play with getting data out from R.\n",
    "\n",
    "We can get the value for the quantile which gives us 95% with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qunif(0.95, lower.tail=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display options.\n",
    "#par(mfrow=c(3,2))\n",
    "#options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "## x-axis values (set like this for clear plotting).\n",
    "#x <- seq(1,6,0.1)\n",
    "## Look at the probability density function ...\n",
    "#d <- dunif(x, min=0, max=6)\n",
    "#plot(d, pch=21, bg='orchid1', main='Probability Density Function')\n",
    "## ... and the cumulative density function.\n",
    "#p <- punif(x, min=0, max=6)\n",
    "#plot(p, pch=21, bg='aquamarine', main='Cumulative Density Function')\n",
    "## Now create a data frame with multiple variables and display what happens when you add them together.\n",
    "#y <- data.frame(runif(1000))\n",
    "#for (i in 1:10) {\n",
    "#    y <- cbind(y, runif(1000))\n",
    "#}\n",
    "## Note that the mean becomes the sum of the means and the variance the sum of the variances.\n",
    "#hist(y[,1], col='khaki', main='Each measurement is from one variable')\n",
    "#hist(y[,1] + y[,2], col='palegreen', main='Each measurement is the sum of two variables')\n",
    "#mean(y[,1])\n",
    "#mean(y[,1] + y[,2])\n",
    "#mean(y[,1] + y[,2] + y[,3])\n",
    "#mean(y[,1]*2)\n",
    "#var(y[,1])\n",
    "#var(y[,1] + y[,2])\n",
    "#var(y[,1] + y[,2] + y[,3])\n",
    "#var(y[,1]*2)\n",
    "## Now for 4 and 10 variables - here we embed a chunk of code in the call to hist():\n",
    "#hist(x={x <- 0; for(i in 1:4){ x <- x + y[,i]}; x}, breaks=20, main='Four variables', xlab='Four variables', col='cadetblue1')\n",
    "#hist(x={x <- 0; for(i in 1:10){ x <- x + y[,i]}; x}, breaks=20, main='Ten variables', xlab='Ten variables', col='peachpuff')\n",
    "## Looking ahead we can compare this to the Normal distribution ...\n",
    "#y <- seq(0, 10, 0.1)\n",
    "#lines(y, 270*dnorm(y, mean=5, sd=1), col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _How to adjust the bin sizes on the histograms_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with histograms is how to organise the bins:\n",
    "* How wide should they be?\n",
    "* Where do you put samples that happen to lie exactly on the boundary between bins?\n",
    "\n",
    "Sturge's rule suggests $n_{bins} = 1 + 3.322log(n_{observations})$; this is the default in R.\n",
    "\n",
    "You can specify a number using `breaks=` and R will try to get close or you can specify the exact breaks you want with a vector or a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(3,2))\n",
    "options(repr.plot.width = 8, repr.plot.height = 8)\n",
    "#x <- rnorm(1000) * 100\n",
    "#sturges <- 1 + 3.322 * log10(length(x))\n",
    "#sturges # <- sturges * 4\n",
    "#histInfo <- hist(x, col='bisque')\n",
    "#hist(x, breaks=sturges, col='darksalmon')\n",
    "#histInfo\n",
    "## Now try some density histograms (i.e. frequency/total).\n",
    "#hist(x, freq=FALSE, main='Density Histogram', sub='default bins', col='lightsteelblue')\n",
    "#hist(x, freq=FALSE, breaks=seq(-400, 400, 20), main='Density Histogram with fixed bins', sub='-400 to 400 in 20s', col='lightsteelblue4')\n",
    "#hist(x, freq=FALSE, breaks=c(-800, -400,-200, -100, -50, 0, 10, 20, 40, 80, 160, 320, 640), main='Density Histogram with a list of bin-sizes', sub='custom vector', col='purple')\n",
    "## Now try a series of ever-increasing number of bins.\n",
    "## range <- max(x) - min(x)\n",
    "#par(mfrow=c(3,3))\n",
    "#b <- c(2, 3, 5, 10, 25, 50, 100, 400, 4000)\n",
    "#for(i in 1:length(b)) {\n",
    "#    hist(x, breaks=b[i], main=b[i], col='lightgreen')\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align:center;\"><tr><td width=\"100\" height=\"20\" style=\"background-color:greenyellow\"></td><td width=\"100\" height=\"20\" style=\"background-color:hotpink\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Binomial Distribution\n",
    "\n",
    "The binomial distribution is the distribution followed when we have each measurement containing _n_ independent trials with a probability of any trial being a success of _p_.\n",
    "\n",
    "We can get the value of the binomial distribution (_n_ given by <code>size</code> and _p_ given by <code>prob</code> at a particular value of _x_) with <code>dbinom</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qbinom(0.95, size=32, prob=0.5)\n",
    "#dbinom(x=2, size=2, prob=0.5, log=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for an entire sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x <- seq(1, 10, 1)\n",
    "#rbinom(x, size=10, prob=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution can be accessed with <code>pbinom</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pbinom(q=1, size=10, prob=0.5, lower.tail=TRUE)\n",
    "#pbinom(q=1, size=10, prob=0.5, lower.tail=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the distribution at a particular quantile can be found with qbinom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qbinom(p=0.95, size=10, prob=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the distribution and create a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(4,2))\n",
    "#x <- seq(0, 300, 1)\n",
    "#for (i in 1:8) {\n",
    "#    x <- seq(0, 4 + 2^i, 1)\n",
    "#    plot(dbinom(x, size=2^i, prob=0.5), main=paste(\"Binomial Distribution with\", 2 ^ i, \"trials per measurement\", sep=\" \"))\n",
    "#}\n",
    "#par(mfrow=c(2,2))\n",
    "#x <- seq(0, 10, 1)\n",
    "#plot(dbinom(x, size=10, prob=0.5), main=\"Binomial Distribution\")\n",
    "#plot(pbinom(x, size=10, prob=0.5, lower.tail=TRUE))\n",
    "#plot(rbinom(1000, size=10, prob=0.5))\n",
    "#hist(rbinom(1000, size=10, prob=0.5), breaks=50)\n",
    "## Looking ahead ...\n",
    "#y <- seq(0, 10, 0.1)\n",
    "#lines(y, 1000*dnorm(y, mean=5, sd=2), col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the format of the data passed to the hist() function call: rbinom(1000, size=10, prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head(rbinom(1000, size=10, prob=0.5), 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Distribution\n",
    "\n",
    "Special case: a binomial with n=1 is a Bernoulli distribution and this occurs quite frequently e.g. a flipping a coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Exercise__: What happens when the number of variables increases\n",
    "\n",
    "Examine what happens for a coin when you have 1, then 2 then 4 then 8 throws. \n",
    "\n",
    "What about a 6-sided dice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,3))\n",
    "#barplot(dbinom(x=seq(0,32,1), size=1, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#barplot(dbinom(x=seq(0,32,1), size=2, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#barplot(dbinom(x=seq(0,32,1), size=4, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#barplot(dbinom(x=seq(0,32,1), size=8, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#barplot(dbinom(x=seq(0,32,1), size=16, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#barplot(dbinom(x=seq(0,32,1), size=32, prob=0.5), main=\"Binomial Distribution\", col=\"yellow\")\n",
    "#par(mfrow=c(1,1))\n",
    "#y <- seq(0, 32, 0.1)\n",
    "#hist(rbinom(n=10000, size=32, prob=0.5), breaks=20)\n",
    "#lines(y, 10000*dnorm(y, mean=16, sd=4), col=\"red\")\n",
    "##par(mfrow=c(2,3))\n",
    "##colours <- c(\"red\", \"green\", \"orange\", \"purple\", \"blue\", \"black\", \"white\", \"pink\")\n",
    "##barplot(dbinom(x=seq(0,32,1), size=1, prob=0.17), main=\"Binomial Distribution\", col=colours)\n",
    "##barplot(dbinom(x=seq(0,32,1), size=2, prob=0.17), main=\"Binomial Distribution\", col=colours)\n",
    "##barplot(dbinom(x=seq(0,32,1), size=4, prob=0.17), main=\"Binomial Distribution\", col=colours)\n",
    "##barplot(dbinom(x=seq(0,32,1), size=8, prob=0.17), main=\"Binomial Distribution\", col=colours)\n",
    "##barplot(dbinom(x=seq(0,32,1), size=16, prob=0.17), main=\"Binomial Distribution\", col=colours)\n",
    "##barplot(dbinom(x=seq(0,32,1), size=32, prob=0.17), main=\"Binomial Distribution\", col=colours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align:center;\"><tr><td width=\"100\" height=\"20\" style=\"background-color:greenyellow\"></td><td width=\"100\" height=\"20\" style=\"background-color:hotpink\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Poisson Distribution\n",
    "\n",
    "This is the distribution for the number of events to have occurred in a time period. For example, \n",
    "It is specified by a single parameter, its mean, lambda.\n",
    "\n",
    "We can get values for specific points on a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dpois(x=1, lambda=1, log=FALSE)\n",
    "#x <- seq(0, 10, 1)\n",
    "#dpois(x, lambda=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the distribution, cumulative distribution and random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,3))\n",
    "#x <- seq(0, 10, 1)\n",
    "## Cumulative probability function\n",
    "#plot(ppois(x, lambda=5, lower.tail=TRUE), col='red')\n",
    "## Probability distibution function for various lambda.\n",
    "#plot(dpois(x, lambda=1), pch=21, bg=1)\n",
    "#points(dpois(x, lambda=2), pch=21, bg=2)\n",
    "#points(dpois(x, lambda=5), pch=21, bg=3)\n",
    "#points(dpois(x, lambda=10), pch=21, bg=4)\n",
    "## Sample of data.\n",
    "#plot(rpois(1000, lambda=5), col='green')\n",
    "## Histogram of a sample of counts (note added labels).\n",
    "## Values of 0, 0.5, and 1 specify that (x, y) should align with the\n",
    "## left/bottom, middle and right/top of the text, respectively.\n",
    "#h <- hist(rpois(1000, lambda=5))\n",
    "#text(h$mids, h$counts, labels=h$counts, adj=c(0.5, -0.5))\n",
    "## Sample of data with large lambda (and colours).\n",
    "#plot(rpois(1000, lambda=100), col=c(1, 2 , 3, 4, 5, 6, 7, 8, 9, 10))\n",
    "## And again, looking ahead to the comparison of a large lambda and a\n",
    "## Normal distribution.\n",
    "#y <- seq(70, 130, 1)\n",
    "#hist(rpois(1000, lambda=100), breaks=20)\n",
    "#lines(y, 5000*dnorm(y, mean=100, sd=10), col='red')\n",
    "##xbar <- barplot(dpois(x=seq(50,150,2), lambda=100))\n",
    "##lines(x=seq(0,100,2), y=dnorm(x=seq(50,150,2), mean=81, sd=4), type='l', col=\"red\")\n",
    "##p <- dpois(x=seq(50,150,1), lambda=100)\n",
    "##d <- dnorm(x=seq(50,150,1), mean=100, sd=10)\n",
    "##p\n",
    "##d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this too tends towards the normal distribution.\n",
    "\n",
    "#### Negative Binomial Distribution\n",
    "\n",
    "A more general version of the Poisson distribution is the negative binomial distribution. This models the number of successes you will encounter in a trial before a specified number of failures occurs (e.g. number of heads before you get three tails). Where the mean and variance are the same in the Poisson distribution, in the negative binomial they are related by:\n",
    "\n",
    "\\begin{equation*} \\sigma^2 = \\mu(1 + \\frac {\\mu}{r} ) \\end{equation*}\n",
    "\n",
    "So when $r = \\infty$ you have the Poisson distribution. You'll come across this when linear modelling with a Poisson distribution (see PMIM202 Modelling notebooks) when overdispersion occurs if the variance exceeds the Poisson mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __The Central Limit Theorem__\n",
    "\n",
    "The distribution these three distributions have been tending towards is the Normal distribution and this tendency is known as the Central Limit Theorem.\n",
    "\n",
    "The i.i.d. assumption is important in the classical form of the central limit theorem, which states that the probability distribution of the sum (or average) of i.i.d. variables with finite variance approaches a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Some Definitions__\n",
    "\n",
    "### _Mode_\n",
    "The most common value. There may be more than one in which case the mode is the local maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v <- c(rnorm(1000, mean=0, sd=1), rnorm(800,mean=4, sd=1))\n",
    "#hist(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Skew_\n",
    "If the distribution is not symetrical and has a lengthened tail in one direction it is known as skew to that direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v <- c(rnorm(1000, mean=0, sd=1), rpois(1000, lambda=3))\n",
    "#hist(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align:center;\"><tr><td width=\"100\" height=\"20\" style=\"background-color:greenyellow\"></td><td width=\"100\" height=\"20\" style=\"background-color:hotpink\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'><tr>\n",
    "    <td style='background-color:red; text-align:center; color: white;'><!--Foundation<!--hr size='5' style='border-color:red; background-color:red;'--></td>\n",
    "    <td style='background-color:yellow; text-align:center;'><!--Level 1<!--hr size='5' style='border-color:yellow; background-color:yellow;'--></td>\n",
    "    <td style='background-color:orange; text-align:center;'><!--Level 2<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:green; text-align:center; color: white;'><!--Level 3<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:blue; text-align:center; color: white;'><!--Level 4<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:purple; text-align:center; color: white;'><!--Level 5<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:brown; text-align:center; color: white;'><!--Level 6<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:black; text-align:center; color: white;'><!--Level 7<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Bibliography__\n",
    "\n",
    "Martin Bland, An Introduction to Medical Statistics, OUP.\n",
    "\n",
    "Michael Crawley, Statistics: An Introduction Using R, Wiley.\n",
    "\n",
    "Michael Crawley, The R Book, Wiley."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
