{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'><tr>\n",
    "    <td style='background-color:red; text-align:center; color: white;'><!--Foundation<!--hr size='5' style='border-color:red; background-color:red;'--></td>\n",
    "    <td style='background-color:yellow; text-align:center;'><!--Level 1<!--hr size='5' style='border-color:yellow; background-color:yellow;'--></td>\n",
    "    <td style='background-color:orange; text-align:center;'><!--Level 2<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:green; text-align:center; color: white;'><!--Level 3<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:blue; text-align:center; color: white;'><!--Level 4<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:purple; text-align:center; color: white;'><!--Level 5<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:brown; text-align:center; color: white;'><!--Level 6<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:black; text-align:center; color: white;'><!--Level 7<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style='border-left:10px solid orange;'><tr>\n",
    "    <td style='padding-left:20px;'>\n",
    "        <h2><i>Swansea University Medical School</i><br/><b>MSc Health Data Science</b></h2>\n",
    "        <h3>PMIM-102 Introduction to Scientific Computing in Healthcare</h3>\n",
    "        <h1><b>Introduction to Programming in R</b></h1>\n",
    "        <h2><b>Exercises</b></h2>\n",
    "        <h2><i>Part 3: Practice with the MIMIC Synthetic Dataset.</i></h2>\n",
    "        <h3><i>October 2020</i></h3>\n",
    "        <h3><b>To-do</b></h3>\n",
    "        <ul><li>Everything.</li></ul>\n",
    "    </td>\n",
    "    <td><img height='300' width='500' src='images/cover.jpg'/></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Aim__: Practice using R and statistical analyses on a typical dataset.\n",
    "\n",
    "The aim of this session is to apply all of the work so far, in particular the Tidyverse, to a fairly lifelike dataset to practice and explore the problem and issues that arise.\n",
    "\n",
    "### __A map of where we're going__\n",
    "\n",
    "1. __Explore__ - Look through the files - what is there, what does it look like.\n",
    "\n",
    "1. __Decide on a research question or area of interest__ - Decide which data you want to use and load it into R.\n",
    "\n",
    "1. __Tidying the data__ - Get the data into the form you want it.\n",
    "\n",
    "1. __Analyse and transform__ - Analyse, organise and process the data.\n",
    "\n",
    "1. __Produce results__ - Statistics, CIs, p-values, graphs, tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Load the Tidyverse__\n",
    "\n",
    "The first thing to do is make sure the library is loaded. If you have not already installed it, do so not using the <code>install.packages()</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-- \u001b[1mAttaching packages\u001b[22m --------------------------------------- tidyverse 1.3.0 --\n",
      "\n",
      "\u001b[32mv\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32mv\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32mv\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32mv\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32mv\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32mv\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32mv\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32mv\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "-- \u001b[1mConflicts\u001b[22m ------------------------------------------ tidyverse_conflicts() --\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mx\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## install.packages('tidyverse')\n",
    "#library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Working Environment__\n",
    "\n",
    "__Create a project and enable git.__ <-- This is important as we will discuss below.\n",
    "\n",
    "Create directories and a working R-script file. You may have a directory/file R/MIMIC.R where you will put the code for the random number generator and another working_MIMIC.R either in the root directory of your project or as R/working_MIMIC.R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Explore the Dataset__\n",
    "\n",
    "We'll have a look at the MIMIC-III dataset (available at [physionet](https://mimic.physionet.org)), where you can also find an explanation of the tables. There is an explanatory paper byt Johnson _et al._\n",
    "\n",
    "AEW Johnson, TJ Pollard, L Shen, L-WH Lehman, M Feng, M Ghassemi, B Moody, P Szolovits, LA Celi, & RG Mark, (2016) Scientific Data, 3, 160035, _Data Descriptor: MIMIC-III, a freely accessible critical care database._ DOI: 10.1038/sdata.2016.35\n",
    "\n",
    "The table data includes data about the primary keys and foreign keys that allow you to reference data from other tables and combine this data with your platform file using joins.\n",
    "\n",
    "### __Reading the data files__\n",
    "\n",
    "Open up the MIMIC directory and review the files that are there - mostly CSV files and a couple of others. In R-Studio, start reading these files in using `read_csv()` following the procedure shown in the Tidyverse notebook.\n",
    "\n",
    "First you will need to read your data file:\n",
    "\n",
    "`admissions <- read_csv(file='admissions.csv')`\n",
    "\n",
    "which will probably produce an error message. This is the difficult moment where many people resort to a non-reproducible workaround like setting the working directory to:\n",
    "\n",
    "`setwd(\"C:/Users/Pete/Documents/HDS/Modules/PMIM102/MIMIC/data/mimic-III/mimic-iii-clinical-database-demo-1.4\")`\n",
    "\n",
    "which won't be the same on everyone's PC and may lead to the data not being included when you save the work for later. If this is all built into a project from the start, you are likely to put data in the logical place for your projects and can make use of utilities like `here()`. You should then be able to use:\n",
    "\n",
    "`admissions <- read_csv(file='data/mimic-III/mimic-iii-clinical-database-demo-1.4/admissions.csv')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#admissions <- read_csv(file='data/mimic-III/mimic-iii-clinical-database-demo-1.4/admissions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may disagree with the formatting choices made by the `read_csv()` function, and can fix that using the procedure below. Sometimes you will have to do this when `read_csv()` just can't cope, for example, try the cptevents file.\n",
    "\n",
    "Notice the parsing error. `read_csv` has chosen a logical column format and we really need character and datetime format. But we can fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cptevents <- read_csv(file='data/mimic-III/mimic-iii-clinical-database-demo-1.4/cptevents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the parsing error. `read_csv` has chosen a logical column format and we really need character and datetime format. But we can fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec <- spec(cptevents)\n",
    "#spec$cols[['description']] <- col_character()\n",
    "#spec$cols[['chartdate']] <- col_datetime('%Y-%m-%d %H:%M:%S')\n",
    "#cptevents <- read_csv(file='data/mimic-III/mimic-iii-clinical-database-demo-1.4/cptevents.csv', col_types=spec)\n",
    "#head(as_tibble(cptevents)) # as_tibble not needed, it's a tibble already, used here for information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Exercise:__ Repeat this for all the files.\n",
    "\n",
    "This may seem like a lot of typing. There is a way to get the names into R using DOS. You can create a text file of the file names using:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dir /b > directory.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which lists the directory contents (dir) but in shortform i.e. just the names (/b) and sends the result to a file (> directory.txt).\n",
    "\n",
    "You can then read the file into R using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir <- read_lines(file='data/mimic-III/mimic-iii-clinical-database-demo-1.4/directory.txt')\n",
    "#head(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use the names as `dir[1]` etc. with the path added using paste (preferably set the path just once in a variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir[1]\n",
    "#path <- 'data/mimic-III/mimic-iii-clinical-database-demo-1.4/'\n",
    "#file_name_with_path <- paste(path, dir[1], sep='')\n",
    "#file_name_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cptevents_file <- paste(path, dir[5], sep='')\n",
    "#cptevents <- read_csv(file=cptevents_file, col_types=spec)\n",
    "#head(as_tibble(cptevents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Watch out for the non-data files__ - you'll need to increment the list `dir[n]` to skip over these. Always check your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Saving the data files__\n",
    "\n",
    "You can now save your data if you wish to a separate file so that you can reload it without having to go through this process.\n",
    "\n",
    "You should decide how this works for you. I tend to work with the original data file and run through the code as that will be robust to updates to the data files. But then I've only used small files, most of my data is read directly from SQL (which you'll do later in the module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved_file <- paste(path, 'processed_data/saved_data_1.RData', sep='')\n",
    "#save(admissions, cptevents, file=saved_file, ascii=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always check - delete the saved objects ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm(admissions)\n",
    "#rm(cptevents)\n",
    "#head(admissions)\n",
    "#head(cptevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and read them back in from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load(file=saved_file)\n",
    "#head(admissions)\n",
    "#head(cptevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can save as CSV files or export to other formats if you wish - see the R libraries especially `haven` for statistical formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Decide on a research question or area of interest__\n",
    "\n",
    "Decide which data you want to use and load it into R. If you have something that interests you, you see how you would approach that problem on this dataset. If, not we'll just work our way through. This step would usually involve discussions about the clinical details of the conditions of interest, the data that is available, ownership etc.\n",
    "\n",
    "Then we'll come up against the need to decide how we decide a patient/record is include - how do you define smoker or drinker for example?\n",
    "\n",
    "How do you define abused child? You might look for GP codes for injuries, but many abused children do not access their GP, so a lack of access might be a clue.\n",
    "\n",
    "These things come more into play in later modules but it is worth keeping these thoughts in mind. We'll progress in a less focussed way that is intended to give you experience of doing the kind of activities that occur in health data science although this may occasionally mean we'll do something to a variable which you might prefer to handle in a different way in the real-world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Tidying the data__\n",
    "\n",
    "Get the data into the form you want it.\n",
    "\n",
    "#### __1. Selecting data from the study period only__\n",
    "\n",
    "Often we have restricted ourselves to a study period. Perhaps this is a period of interest or a period that we know we have good data for. So we may need to exclude any data that has happened before and after a set of dates.\n",
    "\n",
    "If you look at `chartevents`, the charttime runs from 2102 - 2202:\n",
    "\n",
    "Note that `length(chartevents)` produces the width of the table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chartevents_file <- paste(path, 'chartevents.csv', sep='')\n",
    "#chartevents <- read_csv(file=chartevents_file)\n",
    "#spec <- spec(chartevents)\n",
    "#spec$cols[['value']] <- col_character()\n",
    "#spec$cols[['stopped']] <- col_character()\n",
    "#spec$cols[['resultstatus']] <- col_character()\n",
    "#chartevents <- read_csv(file=chartevents_file, col_types=spec)\n",
    "#head(as_tibble(chartevents))\n",
    "#cat('The length of the table is', length(chartevents), '\\n', sep=' ')\n",
    "#cat('The number of entries in chartevents is', (chartevents %>% count())[[1]], '\\n', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a random sample from the data (by number of rows or fractions) and re-arrange the data to get a feel for what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_n(chartevents, 10)\n",
    "#sample_frac(chartevents, 0.00001)\n",
    "#chartevents <- chartevents %>% arrange(charttime)\n",
    "#head(chartevents)\n",
    "#tail(chartevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we'll exclude anything outside 2120-2129."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chartevents <- chartevents %>% filter(charttime>=as.Date('2120-01-01')&charttime<=as.Date('2129-12-31'))\n",
    "#cat('The number of entries in chartevents between 2120 and 2129 (inc) is', (chartevents %>% count())[[1]], '\\n', sep=' ')\n",
    "#head(chartevents)\n",
    "#tail(chartevents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __2. Removing bad data.__\n",
    "\n",
    "We often need to remove data that is incomplete or wrong. But, as mentioned above, should be careful that we are not introducing a bias when we do this. One obvious thing to look out for is a bad date, such as 31<sup>st</sup> June - should you correct this, and how - did they mean 30<sup>th</sup> June or 31<sup>st</sup> July and does it matter? Is the problem systematic or random? If random, fixing it may introduce a systematic error rather than a random one.\n",
    "\n",
    "Look at the `chartevents` data. Remove the missing data for the units of the measurement (assuming that this is indeed an error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat('The number of entries in chartevents before drop_na() is', (chartevents %>% count())[[1]], '\\n', sep=' ')\n",
    "#chartevents <- chartevents %>% drop_na(valueuom)\n",
    "#cat('The number of entries in chartevents after drop_na() is', (chartevents %>% count())[[1]], '\\n', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __3. Re-arranging data into a tidy format.__\n",
    "\n",
    "#### __3.1 Creating your platform file__\n",
    "\n",
    "We usually start with a base file in which we gather the background information for the patients we are including in the study. We add to this all the relevant data from the various concepts we wish to analyse, such as date of first diagnosis, first and last dates of treatments etc.\n",
    "\n",
    "In general, this will be carefully considered during the study design period and depend on the data available and what we want to do with it. But, for this exercise, we'll start with the patient data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patients_file <- paste(path, 'patients.csv', sep='')\n",
    "#dataset <- read_csv(file=patients_file)\n",
    "#sample_frac(dataset, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may then decide we only want to keep a subset of the variables and can use `select()` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset <- dataset %>%\n",
    "#    select(subject_id, gender, dob, dod)\n",
    "#head(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Explore, analyse and transform__\n",
    "\n",
    "Now that we have a base table (platform file), we can add further, single-variable information as we get it for each patient. If we have mutiple values, such as blood tests, diagnoses, we will keep these in separate tables to be processed as and when we need them. For example, we may need to get the trend in blood pressure values for a patient across the study period. For that we would fit a model to all the relevant blood pressure data for the patient and copy the resulting statistic into the platform file.\n",
    "\n",
    "Typically we will want to know the first/last date on which a particular type of event occurred and may want to know a value associated with the event at those dates.\n",
    "\n",
    "### __Getting a first event__\n",
    "\n",
    "Often we just need to know the first time and last time an event has occurred in the study period rather than every time an event occurred. The first we can do is find out about the events. I have found events 220179, 220180 and 220045 seem to have something to do with blood presure and heart rate. MIMIC has a couple of dictionary tables which explain this data more fully (and also refer to the website)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_items_file <- paste(path, 'd_items.csv', sep='')\n",
    "#d_items <- read_csv(file=d_items_file)\n",
    "#spec <- spec(d_items)\n",
    "#spec$cols[['abbreviation']] <- col_character()\n",
    "#spec$cols[['unitname']] <- col_character() # Check this.\n",
    "#spec$cols[['param_type']] <- col_character() # Check this.\n",
    "#d_items <- read_csv(file=d_items_file, col_types=spec)\n",
    "#\n",
    "#d_items %>% filter(itemid==220179|itemid==220180|itemid==220045)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we want to find the first systolic BP reading for each patient, we can try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- chartevents %>% \n",
    "#    filter(itemid==220179) %>%\n",
    "#    group_by(subject_id) %>%\n",
    "#    filter(row_number()==1)\n",
    "#head(first_sysbp_chartevents, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that head() indicates that the data frame is `grouped`. If we want to work on the whole data frame, we need to ungroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat('Number of rows in first_sysbp_chartevents is', (first_sysbp_chartevents %>% count())[[1]], '\\n', sep=' ')\n",
    "#first_sysbp_chartevents <- first_sysbp_chartevents %>% ungroup()\n",
    "#head(first_sysbp_chartevents, 3)\n",
    "#cat('Number of rows in first_sysbp_chartevents is', (first_sysbp_chartevents %>% count())[[1]], '\\n', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can also confirm that the subject_ids should only occur once (this is very useful after doing a join when you may create combinations of tables and consequently multiple entries for some patients. A count of rows won't then be a count of patients and can be very misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat('Number of rows in first_sysbp_chartevents is', (first_sysbp_chartevents %>% count())[[1]], '\\n', sep=' ')\n",
    "#cat('Number of rows in first_sysbp_chartevents is', (first_sysbp_chartevents %>% distinct(subject_id) %>% count())[[1]], '\\n', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other thing comes to mind when exploring the data and that is how many times does each patient have their blood pressure recorded? We can record this at the point we have grouped the filtered data using the `mutate()` function to add the extra information to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    group_by(subject_id) %>%\n",
    "#    mutate(number_220179=n()) %>%\n",
    "#    filter(row_number()==1) %>%\n",
    "#    ungroup()\n",
    "#head(first_sysbp_chartevents, 3)\n",
    "#summary(first_sysbp_chartevents$number_220179)\n",
    "#chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    group_by(subject_id) %>%\n",
    "#    summarise(n(), mean(valuenum), sd(valuenum)) %>%\n",
    "#    head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Visualisation: Plotting the data__\n",
    "\n",
    "We can also plot the data (we could use the base-R code or ggplot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(data=first_sysbp_chartevents, aes(x=charttime, y=valuenum)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Dealing with unexpected data__\n",
    "\n",
    "Occasionally, the exploration will throw-up challenges such as outliers, and there's one in this data. If we try to plot the patients bllod pressure data to get some idea how it varies, we immediately hit a typical problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    group_by(subject_id) \n",
    "#ggplot(data=first_sysbp_chartevents, aes(x=charttime, y=valuenum, group=subject_id, color=subject_id)) + geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to find out what is happening, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    summarise(max(valuenum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we may need to make an educated guess as to where we should consider an outlier would be or we may need to look it up, or we may need to take clinical advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    filter(valuenum<300) %>%\n",
    "#    group_by(subject_id) \n",
    "#ggplot(data=first_sysbp_chartevents, aes(x=charttime, y=valuenum, group=subject_id, color=subject_id)) + geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the format of the lines in the above chart, it might be interesting to see how spread out the blood pressure readings are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- chartevents %>% \n",
    "#    arrange(subject_id) %>%\n",
    "#    filter(itemid==220179) %>%\n",
    "#    filter(valuenum<300) %>%\n",
    "#    group_by(subject_id) %>%\n",
    "#    mutate(first_chart=charttime[1]) %>%\n",
    "#    # The duration created here is in seconds.\n",
    "#    mutate(delta_minutes=as.numeric(charttime-first_chart)/60) %>%\n",
    "#    ungroup()\n",
    "#head(first_sysbp_chartevents, 5)\n",
    "#ggplot(data=first_sysbp_chartevents, aes(x=delta_minutes, y=valuenum, group=subject_id, color=subject_id)) + geom_line()\n",
    "#ggplot(data=first_sysbp_chartevents %>% filter(subject_id==40124), aes(x=delta_minutes, y=valuenum, group=subject_id, color=subject_id)) +\n",
    "#    geom_line()\n",
    "#ggplot(data=first_sysbp_chartevents %>% filter(subject_id==40124&delta_minutes<5000), aes(x=delta_minutes, y=valuenum, group=subject_id, color=subject_id)) +\n",
    "#    geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Examine some statistics__\n",
    "\n",
    "Rather than just look at the values we can see a count of the number of patients that have a value within a range of values using a histogram (i.e. the distribution of the values). ggplot is able to organise the counting for us, we just need to tell it which variable to count and how small a bin size/how many bins we want it to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ggplot(data=first_sysbp_chartevents, aes(x=valuenum, group=subject_id, color=subject_id)) + geom_histogram(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many analyses depend on a Normal distribution of data, we can look to see how Normal this is using Q-Q plots, Shapiro-Wilk test and the Kolmogorov-Smirnov test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qqnorm(first_sysbp_chartevents$valuenum)\n",
    "#qqline(first_sysbp_chartevents$valuenum, col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One process we often use is to transform the data into a form that _is_ Normal - i.e. perform a transformation on the data to bring the plot onto the straight line. Typically this may be a log(), sqrt() or 1/n function.\n",
    "\n",
    "We'll try the sqrt() and, if that's not quite strong enough higher-order tranformations (especially as this gives us practive creating and using a function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cubrt <- function(x)\n",
    "#{\n",
    "#    return(x^(1/3))\n",
    "#}\n",
    "#first_sysbp_chartevents <- first_sysbp_chartevents %>%\n",
    "#    mutate(trans_vn=cubrt(valuenum)) %>%\n",
    "#    filter(trans_vn>0)\n",
    "#ggplot(data=first_sysbp_chartevents, aes(x=trans_vn, group=subject_id, color=subject_id)) + geom_histogram(bins=100)\n",
    "#qqnorm(first_sysbp_chartevents$trans_vn)\n",
    "#qqline(first_sysbp_chartevents$trans_vn, col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, we'll give a log() transformation a go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_sysbp_chartevents <- first_sysbp_chartevents %>%\n",
    "#    mutate(trans_vn=log(valuenum)) %>%\n",
    "#    filter(trans_vn>0)\n",
    "#ggplot(data=first_sysbp_chartevents, aes(x=trans_vn, group=subject_id, color=subject_id)) + geom_histogram(bins=100)\n",
    "#qqnorm(first_sysbp_chartevents$trans_vn)\n",
    "#qqline(first_sysbp_chartevents$trans_vn, col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run some tests on the data. First let's put a number on the normality with the Shapiro Wilk test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shapiro.test(first_sysbp_chartevents$valuenum)\n",
    "#shapiro.test(first_sysbp_chartevents$trans_vn)\n",
    "### A quick check to check that we have this correct.\n",
    "##v <- rnorm(5000)*100 + 100\n",
    "##hist(v)\n",
    "##shapiro.test(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the distribution of the data with a Kolmogorov-Smirnov test or a chi-squared goodness of fit test and, again, visually compare the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ks.test(first_sysbp_chartevents$trans_vn, \"pnorm\", mean=mean(first_sysbp_chartevents$trans_vn), sd=sd(first_sysbp_chartevents$trans_vn))\n",
    "#(first_sysbp_chartevents %>% count())[[1]]\n",
    "#norm <- rnorm((first_sysbp_chartevents %>% count())[[1]], mean=mean(first_sysbp_chartevents$trans_vn), sd=sd(first_sysbp_chartevents$trans_vn))\n",
    "#chisq.test(first_sysbp_chartevents$trans_vn, norm)\n",
    "#\n",
    "#hist(first_sysbp_chartevents$trans_vn, col=rgb(0, 1, 0, 0.5))\n",
    "#hist(norm, col=rgb(1, 0, 1, 0.5), add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feel that the Normal assumption really does not hold then we can use a non-parametric test such as the Wilcoxon / Mann Whitney U tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wilcox.test(first_sysbp_chartevents$valuenum, norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Getting first and last events__\n",
    "\n",
    "It is a simple extension from getting the first to getting the last events for each patient for an event. This could be further extended to getting other values too and makes use of the `spread()` tidyverse function which is very useful for moving data from a form with multiple rows for each patient into separate columns in one row for each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sysbp_chartevents <- chartevents %>% \n",
    "#    # Just select the variables we are going to need.\n",
    "#    select(subject_id, itemid, charttime, valuenum) %>%\n",
    "#    # Order by patient ID.\n",
    "#    arrange(subject_id) %>%\n",
    "#    # Get only the systolic blood pressure data.\n",
    "#    filter(itemid==220179) %>%\n",
    "#    # We don't need the itemid variable anymore so we can remove it to keep\n",
    "#    # things simple.\n",
    "#    select(-itemid) %>%\n",
    "#    # Now work of the patients individually - by grouping things like count()\n",
    "#    # count the numbers for each group (in this case for each group of records\n",
    "#    # with the same subject_id)\n",
    "#    group_by(subject_id) %>%\n",
    "#    # It is often useful to note how many tests each patient has overall.\n",
    "#    mutate(number_sbp_tests=n()) %>%\n",
    "#    # Now select only the first and last test.\n",
    "#    filter(row_number()==1|row_number()==n()) %>%\n",
    "#    # We are going to use `spread()`, so rather than have 1 and n, where n is\n",
    "#    # the number of readings for each patient, we'll change these values to\n",
    "#    # character strings which will become the column titles.\n",
    "#    mutate(sbp_index=ifelse(row_number()==1, 'initial_sbp', 'final_sbp')) %>%\n",
    "#    mutate(sbp_timeindex=ifelse(row_number()==1, 'initial_sbp_date', 'final_sbp_date')) %>%\n",
    "#    # Now we spread the values to columns (but get left with two rows because\n",
    "#    # of the existing data).\n",
    "#    spread(sbp_index, valuenum) %>%\n",
    "#    spread(sbp_timeindex, charttime) %>%\n",
    "#    # Finally we clean up the rows and clear out the duplicates.\n",
    "#    mutate(initial_sbp=max(initial_sbp, na.rm=TRUE), final_sbp=max(final_sbp, na.rm=TRUE)) %>%\n",
    "#    mutate(initial_sbp_date=max(initial_sbp_date, na.rm=TRUE), final_sbp_date=max(final_sbp_date, na.rm=TRUE)) %>%\n",
    "#    filter(row_number()==1) %>%\n",
    "#    # And you must remember to ungroup or you may not get the behaviour\n",
    "#    # you are expecting from here on.\n",
    "#    ungroup()\n",
    "#head(sysbp_chartevents)\n",
    "#sysbp_chartevents %>% distinct(subject_id) %>% count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Add the data to the platform file__\n",
    "\n",
    "We now have a set of data such that all the variables are provided as columns with one row per patient. We can now add this data back to the platform file. We need to check that the data looks correct and that the number of rows is correct and that rows are distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head(dataset)\n",
    "#head(sysbp_chartevents)\n",
    "#\n",
    "#cat('Number of rows in dataset is', (dataset %>% count())[[1]], '\\n', sep=' ')\n",
    "#cat('Number of rows in first_sysbp is', (sysbp_chartevents %>% count())[[1]], '\\n', sep=' ')\n",
    "#dataset2 <- dataset %>% left_join(sysbp_chartevents, by='subject_id')\n",
    "#cat('Number of rows in dataset after join is', (dataset2 %>% count())[[1]], '\\n', sep=' ')\n",
    "#cat('Number of distinct subject_id rows in dataset after join is', (dataset2 %>% distinct(subject_id) %>% count())[[1]], '\\n', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_n(dataset2, 10)\n",
    "## head(dataset %>% filter(!is.na(initial_sbp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __More Exercises__\n",
    "\n",
    "#### _1. Contingency tables_\n",
    "\n",
    "Review the admissions data and create contingency tables and see if there is a correlation between any of the variables and, for example, death.\n",
    "\n",
    "#### _2. Test analyses_\n",
    "\n",
    "#### _2.1 Log tranformations_\n",
    "\n",
    "Repeat the process with the blood pressure but with a blood test that may drop to zero at low levels. Such data is quite common in medical records and responds well to a log transformation.\n",
    "\n",
    "#### _2.2 Correlation_\n",
    "\n",
    "Find two variables that are clearly related and determine their correlation. Experiment with determining the relationship.\n",
    "\n",
    "#### _3. Explore various variables and plots_\n",
    "\n",
    "Try to experiment with examining data using plot() and ggplot(). Look at varying the size of data points and colour by other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"text-align:center;\"><tr><td width=\"100\" height=\"20\" style=\"background-color:greenyellow\"></td><td width=\"100\" height=\"20\" style=\"background-color:hotpink\"></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width='100%'><tr>\n",
    "    <td style='background-color:red; text-align:center; color: white;'><!--Foundation<!--hr size='5' style='border-color:red; background-color:red;'--></td>\n",
    "    <td style='background-color:yellow; text-align:center;'><!--Level 1<!--hr size='5' style='border-color:yellow; background-color:yellow;'--></td>\n",
    "    <td style='background-color:orange; text-align:center;'><!--Level 2<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:green; text-align:center; color: white;'><!--Level 3<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:blue; text-align:center; color: white;'><!--Level 4<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:purple; text-align:center; color: white;'><!--Level 5<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:brown; text-align:center; color: white;'><!--Level 6<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "    <td style='background-color:black; text-align:center; color: white;'><!--Level 7<!--hr size='5' style='border-color:orange; background-color:orange;'--></td>\n",
    "</tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
